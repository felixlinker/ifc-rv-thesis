%!TEX root = ../thesis.tex

\section{Background}


\subsection{Formal Verification of Specifications}
\label{sec:verify-spec}

As already introduced, the work of \citeauthor{Reid17} in \citetitle{Reid17} \cite{Reid17} focusses on verifying specifications, in particular an \gls{isa}, against high level properties.
The key motivation of his work is best summarized in the conclusion of the paper:
\begin{displaycquote}[p.88:22]{Reid17}
    Formal verification of programs is becoming more and more practical but, if the verification is to be meaningful, it must be based on correct architecture specifications for the hardware that the programs run on.
    That is, the specifications are a critical part of the Trusted Computing Base.
    Unfortunately, the size and complexity of architecture specifications is such that it seems inevitable that specifications will contain bugs and our previous work confirms this supposition.

    While it is common to debug specifications by \textit{testing} the specification, this paper proposes a different approach:
    we define a set of formal properties that should hold for the specification and we \textit{formally verify} the architecture specification satisfies these properties.
    We think of the relationship between the properties and the specification as being like the relationship between a nation's constitution and a nation's laws:
    the constitution is concise enough that everyone can read them while the laws are too large for effective review; the constitution can be used to test whether existing or proposed laws are compatible with high level goals; and the constitution is stable and changes very, very slowly.
\end{displaycquote}

These high-level properties comprise the formalization of \textcquote[p.88:2]{Reid17}{cross-cutting features}, i.e. features that describe expected high-level behavior of the architecture.
These have the downside that they are usually hard to grasp for humans since they require a thorough understanding of the system as a whole, yet are powerful since they often (indirectly) touch many aspects of the specification.
In his paper, \citeauthor{Reid17} gives a list of requirements for such cross-cutting properties:
\begin{displaycquote}[pp.88:2-3]{Reid17}
    The central design challenge we face is to create a set of properties that:
    \begin{itemize}
        \item express the major guarantees that programmers depend on;
        \item are concise so that architects can easily review and remember the entire set of properties;
        \item are stable so that architectural extensions don't invalidate large numbers of rules;
        \item and that describe the architecture differently from existing specification to reduce the risk of common-mode failure.
    \end{itemize}
\end{displaycquote}

The aspects of the conciseness and stability of the properties implement the idea of a \enquote{constitution} for an \gls{isa} which links back to the paragraphs quoted above.
The first point, however, more play a role for the practical applicability of the verification process.
If properties, the architecture is verified against, express \enquote{major guarantess that programmers \textins{can} depend} on, they can be used to aid in usage of the platform, e.g. by \gls{os} engineers to utilize the mechanisms of the architecture correctly and thereby to write secures \glspl{os}.
Lastly, the requirement aimed at reducing the \enquote{risk of common-mode failure} aims at other approaches of verifying specifications.
\citeauthor{Reid17} lists three commonly used ways of verifying specifications: \textcquote[p.88:2]{Reid17}{by testing specifications against existing existing implementations; by testing specifications using testsuites used to test implementations; or as a side effect of attempting to formally verify an implementation against a specification}.
These approaches, however, all face the risk of issues with the specification being undetected because the implementation and specification both are affected by the same issue, i.e. the risk of issues being undetected because of common-mode failure.
This risk can be mitigated if the properties the specification will be verified against actually expresses something \textit{new}.

\citeauthor{Reid17} applies his approach to the \gls{mclass} architecture for which not only a natural language but also a machine-readable specification is available.
The machine-readable specification of the \gls{mclass} architecture implements the function \asl{TopLevel} which implements the transition of the architecture from one state to another, i.e. a cycle of the processor.
The natural language specification on the other hand mainly consists of rules that constrain the behavior of the architecture in different situations, i.e. that constrain the transition relation between architectural states that implicitly is given by the \asl{TopLevel} function.

In principle, these two forms of specification also face the risk of common-mode failures.
In practice, however, it turned out that the natural language specification included several rules that described the behavior of the architecture on a very high-level thus meeting aforementioned requirements.
Using these rules as high-level cross-cutting properties, \citeauthor{Reid17} was able to find 12 bugs in the \gls{mclass} specification that despite prior testing had been undiscovered up to this point.

In summary, the aspects of \cite{Reid17} that are relevant for this thesis are:
\begin{enumerate}[label=\alph*)]
    \item the paper precisely argues for why the verification of specifications themselves is important; and
    \item the paper proposes clear requirements for properties to verify an \gls{isa} against.
\end{enumerate}

Additionally, the paper successfully implements this approach by partially verifying the \gls{mclass} architecture.
A downside of this work, however, is that it is limited to verifying single processor transactions only.
This lies in the nature of the properties taken from the natural language specification which only constrain single transitions of the processor.

This thesis attempts to fill this gap and proposes a new way of verifying architectural specifications which will apply to multiple processor transitions.
The work in this thesis therefore also is subject to the same requirements that have been imposed on the high-level properties in \cite{Reid17}.
% TODO: actually compare my results to these requirements

\subsection{Information Flow Control}
\label{sec:ifc}

% TODO: introduce what an HDL is

In \citetitle{Ferraiuolo17} \cite{Ferraiuolo17} by \citeauthor{Ferraiuolo17} the authors formally verify an implementation of the \gls{trustzone} architecture by statically type-checking an information flow policy.
To achieve this, they enhance on the already existing \gls{hdl} language \gls{secverilog}, extending its type system to allow more fine grained modelling of information flow policies.
Therefore, the authors verify an implementation against higher level properties as opposed verifying a specification as done by \citeauthor{Reid17} in \cite{Reid17}.
This thesis takes this general approach and lifts it to be applied to specifications rather than implementations.

\citeauthor{Ferraiuolo17} define an \textit{information flow policy} as a lattice of security labels $ (M, \sqcup, \sqcap) $; with $ \sqsubseteq $ being the partial order on $ M $ as induced by the lattice.
Intuitively speaking, information labelled with $ a \in M $ is allowed to flow to a sink labelled with $ b \in M $ iff $ a \sqsubseteq b $, i.e. information is always allowed to flow up in the lattice but not down.

\begin{example}
    To verify an \gls{trustzone} implementation, \citeauthor{Ferraiuolo17} introduce four information flow labels $ \Sigma = \{ \PT, \PU, \CT, \CU \} $ which stand for public/trusted, public/untrusted, confidential/trusted and confidential/untrusted.
    These labels form the information flow policy lattice $ (\Sigma, \sqcup, \sqcap) $ which is depicted in figure \ref{fig:sec-lattice} as a hasse diagram.
    As you can see, each of these four labels comprises two tokens from two domains of information flow control.
    The first of these domains is the one of \textit{confidentiality} - each of the labels states that a piece of information is either public (\P{}) or confidential (\C{}).
    The second of these domains is the one of \textit{integrity}, i.e. are the values we deal with integrous or - in other words - not malicious?
    Each of the labels states that a piece of information is either trusted (\T{}) or untrusted (\U{}).

    \begin{figure}
        \centering
        \begin{tikzpicture}
            \begin{scope}
                \node (pt) {\PT};
                \node[above right=of pt] (ct) {\CT}
                    edge (pt);
                \node[above left=of pt] (pu) {\PU}
                    edge (pt);
                \node[above right=of pu] (cu) {\CU}
                    edge (ct)
                    edge (pu);
            \end{scope}
        \end{tikzpicture}
        \caption{Security lattice for verifying an \gls{trustzone} implementation \cite{Ferraiuolo17}}
        \label{fig:sec-lattice}
    \end{figure}

    It can be seen in the diagram depicting the lattice of security labels (fig. \ref{fig:sec-lattice}) that public information is always allowed to flow to confidential sinks but not vice versa and that trusted information is always allowed to flow to untrusted sinks but not vice versa.
    Intuitively, this means that trusted parts of the architecture must only receive trusted data and that confidential data must be handled by confidential parts of the architecture.
\end{example}

To implement the actual \textit{control} of such an information flow policy, \citeauthor{Ferraiuolo17} introduce the \gls{hdl} language \gls{secverilogbl} that builds upon the \gls{hdl} \gls{secverilog}.
The core of both of these languages when it comes to information flow control is a type-system that adds the syntax to the core \gls{hdl} to allow for annotating variables with security labels and enables verifying an information flow control policy by static type-checking.
In \gls{secverilog}, variables are typed by labels of the respective information flow control policy.
The type of a variable is described either by a label $ l \in M $ directly, by the conjunction $ \sqcap $ or disjunction $ \sqcup $ of two labels or by a type-level function $ f $ that maps some program variable $ v $ to a type.
\gls{secverilogbl} enhances on this by tracking security labels not only per variable but also per bit and array element and therefore allows for more fine grained annotation of the \gls{hdl} code and also adds the mechanism to downgrade information.
Since information is not allowed to flow \enquote{down} in the lattice, downgrading can be understood best as a typecast that allows such behavior.
In some \gls{hdl} programs, it might be necessary to allow for insecure flows (in regard to the information flow policy) of information.
In those cases, a programmer can use \lstinline[mathescape]{downgrade(e, $ \tau $)} to annotate the expression \lstinline{e} as being of type $ \tau $, regardless of any prior annotations.

In total, \gls{secverilogbl} knows seven ways to express:
\begin{align*}
    \text{Types } \tau ::= l \mid \tau_1 \sqcup \tau_2 \mid \tau_1 \sqcap \tau_2 \mid x \mapsto \tau \mid f(x) \mid \textit{if $ e^\tau $ $ \tau_t $ $ \tau_f $} \mid \textit{case $ e^\tau $ $ \tau_1 $ \dots $ \tau_n $}
\end{align*}

As can be seen above, types are either given as simple labels of the information flow policy $ (M, \sqcup, \sqcap) $, as the disjunction or conjunction of two types, as a mapping from an index variable $ x $ to some type, as the application of some program variable $ x $ to the function $ f $ or as an $ \textit{if} $- or $ \textit{case} $-expression where $ e^\tau $ is a pure-expression, i.e. side-effect free.
Types of the form $ f(x) $ are called \textit{dependent types} because the type depends on the value of some program variable $ x $.
$ e^\tau $ in $ \textit{if} $- or $ \textit{case}- $ expressions might also contain program variables; if it does, these expressions also form dependent types.

Types are of a certain kind:
\begin{align*}
    \text{Kinds } k ::= l \mid \texttt{int} \rightarrow k
\end{align*}

Any type is of kind $ l $.
Furthermore, the type $ x \mapsto \tau $ is of kind $ \texttt{int} \rightarrow k $ where $ k $ is the kind of $ \tau $.
However, when type-checking is performed, types of kind $ l $ are lifted to be of kind $ \texttt{int} \rightarrow l $ such that every type is a partial function from bit indices to information flow labels.

% TODO: Move to end of the section
% They evaluated their approach by successfully finding some known bugs in the Arm architecture.
% TODO: evaluate their results more strongly and compare them to mine

\begin{example}
    The following snippet shows the type annotation of parts of a register file definition in \gls{secverilogbl}:
    \begin{lstlisting}[
        language=SecVerilogBL,
        label={snpt:reg-file},
        caption={A register file code segment \cite{Ferraiuolo17}}
    ]
        reg [0:31] {world(ns)} read;
        reg [0:31] { i -> j -> world(reg_ns[i]) } mem[0:1023];
        reg {PT} reg_ns [0:1023];
        (*\dots*)
        if(ns == 1) begin (*\label{ln:assignment}*)
            read = (reg_ns[read_addr] == 1) ?
                mem[read_addr] : 32'b0;
        end else begin
        (*\dots*)
    \end{lstlisting}

    The variables \lstinline{read} and \lstinline{reg_ns} illustrate the purpose of lifting types to higher kinds.
    Both types \lstinline{world(ns)} and \lstinline{PT} are of kind $ l $, yet they are used to annotate variables that store more than one bit.
    % TODO: This is not explicitly mentioned; the definition only allows lifting of l not arbitrary kinds k
    Because \lstinline{read} is a register with 32 bits, \lstinline{world(ns)} is lifted to \lstinline{i -> world(ns)}, i.e. each element of \lstinline{read} is of the dependent type \lstinline{world(ns)}, and since \lstinline{reg_ns} is an array of 1024 registers of width 1, \lstinline{PT} is lifted to \lstinline{i -> j -> PT}, i.e. each array element is of type \lstinline{j -> PT}, i.e. each array element's bits are of type \lstinline{PT}.

    In this example, the variable \lstinline{ns} refers to the \textit{security state} of the \gls{trustzone} architecture.
    The \gls{trustzone} architecture not only knows different privilege but also security states which can either secure-state (meant to handle confidential data) or non-secure-state (meant to handle only non-confidential data).
    The variable \lstinline{ns} in the implementation of the \gls{trustzone} architecture by \citeauthor{Ferraiuolo17} indicates whether the architecture currently is in secure- or non-secure-state.

    Starting in line \ref{ln:assignment}, it can be seen how dependent types work in practice.
    The function \lstinline{world} maps 0 to \lstinline{CT} and 1 to \lstinline{PU}.
    The \lstinline{if}-statement first checks whether \lstinline{ns} equals 1, in which case \lstinline{read} would be of type \lstinline{PU}.
    If this is the case, the register \lstinline{read} shall be written with \lstinline{mem[read_addr]} but only if the type of that also is of \lstinline{PU} which is checked by ensuring that \lstinline{reg_ns[read_addr]} also equals one.
    In this case, since each element's type of \lstinline{mem} depends on \lstinline{reg_ns}, the assignment is safe since obviously, a variable annotated with type \lstinline{PU} can be written with a value of the same type.

    If the check was omitted and when \lstinline{ns == 1}, \lstinline{read} would be written with \lstinline{mem[read_addr]} when \lstinline{reg_ns[read_addr] == 0}, a variable of type \lstinline{PU} would be written with a value of type \lstinline{CT}.
    But since $ \CT \not \sqsubseteq \PU $, this would result in a type-checker error.
\end{example}

The details of this type-system are given by a collection of typing rules.
These rules are written as proofs of sequent calculus.

\begin{example}
    Consider this example of a proof written in sequent calculus:
    \begin{prooftree}
        \AxiomC{$ A $}
        \AxiomC{$ B $}
        \BinaryInfC{$ C $}
    \end{prooftree}

    This proof states that the formula $ C $ can be derived from the formulas $ A $ and $ B $ or more formally that: $ A, B \vdash C $.
\end{example}

In the context of type systems, formulas used in proofs of sequent calculus often are so called \textcquote{Ferraiuolo17}{typing judgements} where some \textit{environment} types some \textit{expression}, e.g. if $ X $ is a type environment, $ x $ an expression and $ \tau $ a type, one possible typing judgement would be $ X \vdash x : \tau $ which means that $ x $ is of type $ \tau $ under the environment $ X $.
In \cite{Ferraiuolo17} three environments are introduced:

\begin{description}
    \item[Standard environment] $ \Gamma $ maps variables to their respective type $ \tau $.
    \item[Width environment] $ \W $ maps variables to their respective bit vector length.
    \item[Kind environment] $ \Theta $ maps types $ \tau $ to their respective kind $ k $.
\end{description}

\citeauthor{Ferraiuolo17} introduce eight typing rules; these are for constant expressions and variables, logical and arithmetic expressions, bit-vector concatenation and shifting as well as array indexing.
An overview of some typing rules of \cite{Ferraiuolo17} can be found in figure \ref{fig:type-rules}\footnote{%
    It will turn out that only these typing rules are relevant in context of this thesis.
}.
The most simple type system rule probably is T-Const which types constant expressions $ n $.
% TODO: reflect on why it is sensible to assume that constants are trusted in their scenario but not in ours
These are always of type $ \bot $, i.e. \PT, and of the corresponding width $ w $.
The other type system rules share a pattern.
They assume one or two expressions ($ e $ or $ e_1 $ and $ e_2 $) to be typed in $ \Gamma; \W; \Theta $ and ensure that their corresponding types ($ \tau $ or $ \tau_1 $ and $ \tau_2 $) are of the right kind in $ \Theta $.
Then, they create a new type ($ \tau $ or $ \tau' $) and infer a type judgement for a new expression involving $ e $, $ e_1 $ or $ e_2 $ and maybe some constant $ n $.
This structure of type system rules follows the pattern of an inductive proof or inductive definition of a set where T-Const and T-Var (the typing rule for variables) are the start of induction.

When the \gls{secverilogbl} code is being type-checked, it is checked whether all right side of assignments are $ \sqsubseteq $-greater than the respective left sides taken together with the label of the program counter.
This means that information is only considered trusted if also the program counter can be considered to be trusted and data is considered to be confidential if either the data itself or the program counter is confidential.

\begin{figure}
    \centering
    \begin{subfigure}[t]{.5\linewidth}
        \begin{prooftree}
            \AxiomC{}
            \UnaryInfC{$ \Gamma; \W; \Theta \vdash n: \bot, w $}
        \end{prooftree}
        \caption{T-Const}
    \end{subfigure}

    \begin{subfigure}[t]{.5\linewidth}
        \begin{prooftree}
            \alwaysNoLine
            \AxiomC{$ \Gamma; \W; \Theta \vdash e_1 : \tau_1, w $}
            \UnaryInfC{$ \Theta \vdash \tau_1 : \texttt{int} \rightarrow l $}

            \AxiomC{$ \Gamma; \W; \Theta \vdash e_2 : \tau_2, w $}
            \UnaryInfC{$ \Theta \vdash \tau_2 : \texttt{int} \rightarrow l $}

            \BinaryInfC{$ \tau = i \mapsto \tau_1( i) \sqcup \tau_2(i) $}

            \singleLine
            \UnaryInfC{$ \Gamma; \W; \Theta \vdash e_1 \circ e_2 : \tau, w $}
        \end{prooftree}
        \caption{T-Logical for $ \circ \in \{ \land, \lor \} $}
    \end{subfigure}

    \begin{subfigure}[t]{.5\linewidth}
        \begin{prooftree}
            \alwaysNoLine
            \AxiomC{$ \Gamma; \W; \Theta \vdash e_1 : \tau_1, w $}
            \UnaryInfC{$ \Theta \vdash \tau_1 : \texttt{int} \rightarrow l $}

            \AxiomC{$ \Gamma; \W; \Theta \vdash e_1 : \tau_2, w $}
            \UnaryInfC{$ \Theta \vdash \tau_2 : \texttt{int} \rightarrow l $}

            \BinaryInfC{$ \tau = i \mapsto \bigsqcup_{j \in [1, i]} (\tau_1(j) \sqcup \tau_2(j)) $}

            \singleLine
            \UnaryInfC{$ \Gamma; \W; \Theta \vdash e_1 \circ e_2 : \tau, w $}
        \end{prooftree}
        \caption{T-Arith for $ \circ \in \{ +, - \} $}
    \end{subfigure}

    \begin{subfigure}[t]{.5\linewidth}
        \begin{prooftree}
            \alwaysNoLine
            \AxiomC{$ \Gamma; \W; \Theta \vdash e : \tau, w $}
            \AxiomC{$ \Theta \vdash \tau : \texttt{int} \rightarrow l $}
            \BinaryInfC{$ \tau' = i \mapsto \ite{(i < n)}{\tau(i - n + 1)}{\bot} $}

            \singleLine
            \UnaryInfC{$ \Gamma; \W; \Theta \vdash e \ll n : \tau', w $}
        \end{prooftree}
        \caption{T-LShift}
    \end{subfigure}

    \begin{subfigure}[t]{.5\linewidth}
        \begin{prooftree}
            \alwaysNoLine
            \AxiomC{$ \Gamma; \W; \Theta \vdash e : \tau, w $}
            \AxiomC{$ \Theta \vdash \tau : \texttt{int} \rightarrow l $}
            \BinaryInfC{$ \tau' = i \mapsto \ite{(i > w - n)}{\bot}{\tau(i + n)} $}

            \singleLine
            \UnaryInfC{$ \Gamma; \W; \Theta \vdash e \gg n : \tau', w $}
        \end{prooftree}
        \caption{T-RShift}
    \end{subfigure}
    \caption{A selection of typing rules for SecVerilogBL expressions \cite{Ferraiuolo17}}
    \label{fig:type-rules}
\end{figure}

In summary, the lattice of security labels taken together with the type system built on top of such a lattice implements three concepts:
\begin{itemize}
    \item A lattice $ (M, \sqcup, \sqcap) $ implements a information flow policy
    \item The typing rules implement information flow tracking
    \item Type-checking implements information flow control
\end{itemize}

\citeauthor{Ferraiuolo17} used these three concepts to verify an implementation of the \gls{trustzone} architecture.
In doing so, they first implemented the architecture as a prototype and used the information flow policy to ensure that it did not contain bugs.
After this, they deliberately added bugs to their implementation that have been found in other implementations of the \gls{trustzone} architecture and checked whether they were able to find these bugs.
It turned out that their approach was able to detect all bugs besides those which were related to downgrading, i.e. the approach of type-checking information flow control policies gives a strong security assurances with the exception of bugs that due to downgrading expressions.

In this thesis, the concept of an information flow control policy and information flow tracking will serve to define higher-level properties to verify an \gls{isa} against.
To achieve this, it must be tackled how such an information flow policy as proposed by \citeauthor{Ferraiuolo17} can be applied to \glspl{isa} such that \begin{enumerate*}[label=\alph*)]
    \item the labels can be tracked throughout the architecture by a model checker, and
    \item the policy can be controlled by the model checker.
\end{enumerate*}, i.e. how can the two concepts of information flow tracking and control be implemented using a model checker?
% TODO: Do I answer above questions?

\subsection{RISC-Architectures}
\label{sec:riscs}

As a target of verification, this thesis will work with \gls{risc} architectures.
In \citetitle{Hennessy12}, \gls{risc} architectures are defined by three main concepts \cite[p.C-4]{Hennessy12}:
\begin{itemize}
    \item Only load and store instructions affect or touch memory
    \item All other instructions work on registers only and always modify the full width of registers
    \item There are very few instructions and their encoding is mostly homogenous
\end{itemize}

The latter aspect coined the name \textit{reduced} instruction set computer architecture.
\gls{risc} architectures are often times understood as the counterparts to \gls{cisc} architectures which describe all architectures that do not implement aforementioned \gls{risc}-properties.
The most prominent example of a \gls{cisc} architecture is the \gls{x86} architecture which is implemented by most processors manufactured by intel.

In this section, three \gls{risc} architectures will be introduced: the \gls{arm} architecture, \gls{mips} and \gls{riscv}.
It will turn out that these architectures can mainly be differentiated by the balance of customizability vs. feature-richness.
Whereas the \gls{riscv} architecture is most customizable it also supports the fewest features out of the box.
On the other hand, the \gls{arm} architecture is very feature-rich but not very much customizable.
The \gls{mips} architecture strikes a middle-ground of these two extremes.

The goal of this section is to illustrate the features and fundamental design that comes with realistic and realistic \gls{risc} architectures.
It was decided to focus on \gls{risc} architectures as a target of verification because their simpler approach to \glspl{isa} makes them far easier to analyze and model than \gls{cisc} processors.
Using a \gls{risc} architecture will allow for implementing an architecture in scope of this thesis while the results will still be applicable and comparable to real-world \glspl{isa} that are in use as of today.
Although choosing a \gls{risc} architecture as a target of verification already embodies a facilitates an easier implementation of the approach of this thesis, verifying a complete architecture still might be out of scope to be verified as part of a master thesis.
Introducing more than one \gls{risc} architectures will allow for choosing parts to exclude in the verification model without harming the significance of the thesis's results.

\subsubsection{Arm}

The \gls{arm} architecture knows three \textit{profiles}:
\begin{itemize}
    \item The generic \textit{application profile} Armv8-A,
    \item the \textit{real-time profile} Armv8-R designed for deployment scenarios in which real-time responses from a processor is crucial, e.g. in aviation,
    \item and the \textit{microcontroller} profile Armv8-M aimed at embedded systems.
\end{itemize}

Here, it will be focused on the Armv8-A profile.
The \citetitle{Armv8} \cite{Armv8} introduces the \gls{arm} A-class architecture as a \gls{risc} architecture with three key properties:
\begin{displaycquote}[p.A1-34]{Armv8}
    \begin{itemize}
        \item A large uniform regsiter file.
        \item A \textit{load/store} architecture, where data-processing operations only operate on register contents, not directly on memory contents.
        \item Simple addressing modes, with all load/store addresses determined from register contents and instruction fields only.
    \end{itemize}
\end{displaycquote}

These properties already meet most of the aspects of \gls{risc} architectures as defined in \cite{Hennessy12}.
When it comes to the aspect of a homogenous instruction set, the \gls{arm} architecture makes some trade-offs on this aspect to support the three profiles available.
The \gls{arm} architecture knows three instruction sets: A64, a fixed-length 32-bit encoding instruction set for 64-bit systems, A32, a fixed 32-bit encoding length-instruction set for 32-bit systems, and T32, a variable-length instruction set that uses both 16- and 32-bit encodings to support compressed instructions.
The Armv8-A architecture eases the challenge of correctly decoding these different instruction sets by the concept of \textit{execution states}.
The Armv8-A supports to of these execution states: AArch64, a 64-bit execution state, and AArch32, a 32-bit execution state.
An \gls{arm} A-class processor accepts to receive A64 instructions when in the AArch64 execution state and A32 or T32 instructions when in the AArch32 execution state.

The Armv8-A specification by standard defines how the processor interacts with memory which includes the specification of a cache and a memory model covering virtual addresses, memory access order control, memory access synchronization, and application level memory restrictions.
Furthermore, it is defined how processors work in a multi-processor setup and how debugging of the architecture works.
The Armv8-A architecture also supports floating point and vector arithmetic standardly.

If these features do not suffice for a specific use-case, there are nine optional extensions available that can be supported by an Armv8-A processor which include an extension for accelerating cryptographic tasks, for enhancing the reliability, availability and serviceability of the processor, for monitoring and profiling, for enhanced vector arithmetic, and for memory partitioning.

As for registers, the Armv8-A architecture supports the most versatile types of registers of all \gls{risc} architectures to be compared in this thesis.
Depending on the execution state, 13 to 31 32- or 64-bit registers are supported.
Additional to this, there is a \gls{pc}, a dedicated \gls{sp} and some exception link registers.
A general purpose register is used as the standard \gls{lr}.
Furthermore, there are 32 64- or 128-bit registers for floating point and vector arithmetic and other \glspl{csr} that hold status information of the architecture.

\subsubsection{MIPS}

As opposed to the \gls{arm} architecture, the \gls{mips} architecture does not only support a smaller range of registers, it also provides fewer features by standard, i.e. without extensions.
It introduces itself in the introductory document \citetitle{MIPS} \cite{MIPS} as: \textcquote[p.21]{MIPS}{based on a fixed-length, regularly encoded instruction set \textelp{which} uses a load/store data model, in which all operations are performed on operands in processor registers, and main memory is accessed only by load and store instructions}.
As for the aspect of a large, uniform register file, \gls{mips} supports 32 32- or 64-bit registers the first of which is hardwired to zero, a \gls{pc} and some \glspl{csr}.
Contrary to the \gls{arm} architecture, there are no dedicated \glspl{lr} or \gls{sp}.
As indicated by the options in the register width, \gls{mips} supports both a 32- and a 64-bit architecture and instruction sets.

\gls{mips} comes with less features out of the box than the \gls{arm} architecture; the specification only touches memory interaction including memory virtualization and cache, debugging and the interaction with a standard coprocessor that implements floating point arithmetic.
\gls{mips}, however, is far more customizable than the \gls{arm} architecture.
Whereas in case of the latter, customizability is only given by choosing different extensions, a processor does not need to implement all features defined in the \gls{mips} specification to be \gls{mips} compliant.
Certain features can be left out which is called \textit{subsetting} of the architecture.
Additionally to that, there also are extensions to the architecture.
\gls{mips} allows to extend the architecture by user defined instructions, compressed instructions, enhanced media processing, enhanced geometry processing, smart card or object interaction, signal processing, multi threading, \gls{os} virtualization, vector arithmetic and an extensions aimed specifically at microcontrollers.

\subsubsection{RISC-V}

\gls{riscv} was originally presented in the technical report \textit{UCB/EECS-2011-62} by the University of California in May 2011 \cite{RiscVISA-org} and has undergone many changes since then.
\gls{riscv}'s architectural specification is divided into two volumes: volume specifies 1 the base user-level \gls{isa} which is separated into several modules whereas volume 2 defines the privileged architecture and instruction set but still only is available as a draft.
The privileged architecture is not divided into modules but rather \textit{functional groups} that define certain aspects of privileged computing.
Such groups include for example machine- and supervisor-level \glspl{isa} and the description of a platform level interrupt controller.

% TODO: Add motivation/goals of RISC-V

This thesis works with version 2.2 of volume 1 \cite{RiscVISA} and version 1.1 of volume 2 \cite{RiscVISAP}.
\gls{riscv} understands itself as a highly customizable architecture.
Currently, there are four variants of a base integer instruction set - one of which must be implemented by any \gls{riscv} processor - and 13 optional extensions.
The base integer instruction sets include instructions for integer arithmetic, memory operations (loads and stores), control transfer (jumps and branches) and platform management (environment calls and status register operations).
The base integer instruction sets mainly differ in the word-size and register number.
To cope with these differences, they also make small adjustments to some functionalities but only slightly change the instruction set itself.
These four base integer instruction sets are given by:
\begin{description}
    \item[RV32I] Base integer instruction set
    \item[RV32E] Base integer instruction set for embedded computing
    \item[RV64I] Base integer instruction set for a 64-bit architecture
    \item[RV128I] Base integer instruction set for a 128-bit architecture
\end{description}

The \gls{riscv} manual differentiates between standard and non-standard extensions but only introduces standard ones.
A standard extension is meant to be compatible with any other standard extension and should be \textcquote{RiscVISA}{generally useful} whilst non-standard extensions might add support for more niche use-cases and do not need to be compatible with all standard extensions.

The set of functionalities offered by standard extensions begins at quite low level with the probably most mundane being the standard extension for integer multiplication and division.
You can find a list of all standard extensions in table \ref{tbl:rv-exts}.

\begin{table}
    \centering
    \begin{tabular}{| c | l |}
        \hline
        \textbf{M} & Integer multiplication and division \\
        \textbf{A} & Atomic instructions \\
        \textbf{F} & Single-precision floating-point arithmetic \\
        \textbf{D} & Double-precision floating-point arithmetic \\
        \textbf{Q} & Quad-precision floating-point arithmetic \\
        \textbf{L} & Decimal floating-point arithmetic \\
        \textbf{C} & Compressed instructions \\
        \textbf{B} & Bit manipulation \\
        \textbf{J} & Dynamically translated languages \\
        \textbf{T} & Transactional memory \\
        \textbf{P} & Packed-SIMD instructions \\
        \textbf{V} & Vector operations \\
        \textbf{N} & User-level interrupts \\
        \hline
    \end{tabular}
    \caption{All \gls{riscv} standard extensions}
    \label{tbl:rv-exts}
\end{table}

A subset of the \gls{riscv} \gls{isa} is described by a so called \textcquote{RiscVISA}{\gls{isa} naming string} which comes in the following form:

\begin{grammar}
    <naming-string> ::= `RV' (`32' | `64' | `128') (`I' | `E') <extensions>
\end{grammar}

An example for a naming string is the very common \gls{isa}-subset RV64IMAFD which officially is abbreviated by RV64G.
This subset includes the integer multiplication and division, user-level interrupts, atomic instructions, single-precision and double-precision floating-point arithmetic extensions.

A \gls{riscv} core consists of multiple \glspl{hart}.
Each \gls{hart} controls its own set of registers including a \gls{pc} and is equipped with its own instruction fetch unit.
However, multiple \glspl{hart} share the same memory.

A \gls{hart} might either control 16 or 32 general purpose registers which are named from x0 to x31.
All but one instruction sets support 32 general purpose registers whereas the exception to this is the base instruction set aimed at embedded computing, RV32E, which only supports 16 general purpose registers.

Similarly to the \gls{mips} architecture, the first of these general purpose registers is hardwired to zero and for example can be used as a target register when the result of an instruction is not needed.
Also, there is no dedicated \gls{lr} or \gls{sp}.
\gls{riscv} supports up to 4096 \glspl{csr}.

\subsubsection{Summary}

In the last the sections, it was shown that the \gls{arm}, \gls{mips}, and \gls{riscv} architectures implement the three main properties of \cite{Hennessy12} characterizing \gls{risc} architectures: a small and uniformly encoded instruction set, a large and uniform register file and a load/store architecture.
Whereas the \gls{arm} architecture supported customizability only by a list of extensions and \gls{mips} added user defined instructions and allowed subsetting its core specification, \gls{riscv} took the idea of customizability and made it part of the core idea of the architecture.
\gls{riscv} supports the most simple yet fully specified processor in form of the RV32E.
It was this degree of customizability and simplicity that led to the decision to use \gls{riscv} as a target of verification.
There are no major features \gls{riscv} lacks in that are crucial to the concept of a \gls{risc} architecture.

\subsection{Processor Vulnerabilities}

\subsubsection{Processors and their Ecosystem}

\subsubsection{Common Attack Vectors}

\subsection{Information Flow Control}

\subsection{Model Checking}

Model checking is a technique that falls into the domain of formal verification.
It is one way to prove that a given system complies with a given specification.
\citeauthor{Baier08} introduce model checking in their book \citetitle{Baier08} \cite{Baier08} as:
\begin{displaycquote}[p.7ff.]{Baier08}
    \textit{Model-based} verification techniques are based on models describing the possible system behavior in a mathematically precise and unambiguous manner. \textelp{}
    This provides the basis for a whole range of verification techniques ranging from an exhaustive exploration (model checking) to experiments with a restrictive set of scenarios in the model (simulation), or in reality (testing). \textelp{}

    Model checking is a verification technique that explores all possible system states in a brute-force manner.
    Similar to a computer chess program that checks possible moves, a model checker, the software tool that performs the model checking, examines all possible system scenarios in a systematic manner.
    Int his way, it can be shown that a given system model truly satisfies a certain property. \textelp{}

    Typical properties that can be checked using model checking are of a qualitative nature:
    Is the generated result OK?,
    Can the system reach a deadlock situation, e.g., when two concurrent programs are waiting for each other and thus halting the entire system?
    But also timing properties can be checked:
    Can a deadlock occur within 1 hour after a system reset?, or, Is a response always received within 8 minutes?
\end{displaycquote}

Model checking therefore deals with two parts: Firstly, a model of some system, secondly, properties formalized on the basis of some specification.
Systems to be model checked can come in many forms.
They range from software libraries over hardware designs to embedded controllers.
The same is true for specifications.
Those can be fully fledged \textit{actual} specifications that describe the requirements to system exhaustively or more higher level properties that generally should apply to systems such as deadlock freeness as mentioned in \cite{Baier08}.

More technically, in model checking some system is taken and transformed into a model using a formal language like \gls{promela} (cf. section \ref{sec:spin}) and a specification is taken and transformed into a property usually expressed in some formal logic, e.g. \gls{ltl}.
Then it is checked via a model checker whether the system model models the formal property.
Note that \enquote{model} in this context is ambiguous.
One the one hand this term refers to the model of the system as a simplified description.
On the other hand, this term refers to the logical models-relation $ \models $ which is actually being checked.

An overview of model checking is given in figure \ref{fig:model-checking}.
There, the idea and purpose of model checking is depicted.
In summary, model checking is a technique that allows to solve the problem of ensuring that a system complies with a specification.
By translating the system into a model and the specification into a formal property this problem can be translated into \textit{checking} whether the model \textit{models} the formal property.

\begin{figure}
    \centering
    \begin{tikzpicture}
        \tikzstyle{box}=[draw,rectangle,minimum width=2cm,minimum height=1cm,text width=2cm,align=center]
        \node[box] (system) {System};
        \node[box] (specification) [right=3cm of system] {Specification}
            edge[draw=none] node[midway] (comply) {complies with?} (system);

        \node[box] (model) [below=of system] {Model}
            edge[<-] (system);
        \node[box] (properties) [below=of specification] {Formal Property}
            edge[draw=none] node[midway] (models) {$ \models $?} (model)
            edge[<-] (specification);

        \draw[->] (comply) to (models);
    \end{tikzpicture}
    \caption{Overview on Model Checking}
    \label{fig:model-checking}
\end{figure}

\subsubsection{SPIN}
\label{sec:spin}

\gls{spin} (which stands for \textit{S}imple \textit{P}romela \textit{IN}terpreter) is a model checker which has been originally developed by Bell Labs and has been made freely available since the nineties.
As its name already suggests, it uses \gls{promela} as input language.
\textit{The Spin Model Checker: Primer and Reference Manual} which has been used as source for this section, describes \gls{spin} initially as follows:
\begin{displaycquote}[p.1]{SpinManual}
    \gls{spin} can be used to verify correctness requirements for systems of concurrently executing processes.
    The tool works by thoroughly checking either hand-built or mechanically generated models that capture the essential elements of a distributed systems design.
    If a requirement is not satisfied, \gls{spin} can produce a sample execution of the model to demonstrate this.
\end{displaycquote}

As indicated by the quote, \gls{spin} focusses heavily on the verification of distributed or parallel systems.
This is reflected not only in its input language but also in the way how properties are expressed about models.
For an introduction by example to \gls{promela}, cf. snippet \ref{snpt:spin-exm}.
\gls{promela} relies on describing systems as sets of processes that run in parallel where parallel means that each process can advance its state (generally) independent of other processes\footnote{%
    We added the restriction \textit{generally} to the claim because processes can be set up such that they deliberately wait for other processes to send them a message or set some shared state accordingly.
    However, such mechanisms where processes depend on each other always need to be implemented accordingly.
}.

In snippet \ref{snpt:spin-exm}, two processes of the same type \lstinline{user} are declared in line \ref{ln:proc}.
The idea of this snippet is to implement and verify an algorithm that grants these two processes mutually exclusive access to the critical region spanning lines \ref{ln:crit-start}-\ref{ln:crit-end}.
This is ensured by the assertion in line \ref{ln:assert} since variables in \gls{spin} are always initialized to 0 - if two processes had access to the critical region at the same time, \lstinline{cnt} would become 2 at some point.

The details of the protocol implemented in lines \ref{ln:excl-start}-\ref{ln:excl-end} the purpose of which is to grant mutual exclusive access to the critical region are not relevant for this thesis.
However, this part of code gives you an indication for how models written in \gls{promela} look like.
Besides \lstinline{if} statements and labels similar to those in C (cf. line \ref{ln:label}), \gls{promela} supports \lstinline{do}-loops to control process execution flow.
\lstinline{do}-loops run indefinitely until they are exited manually by a \lstinline{break} statement.

As data types, \gls{promela} knows three categories of them: processes, message channels and data objects.
Data objects comprise atomic data types such as \lstinline{byte}, \lstinline{bool}, \lstinline{int}, etc. as well as complex data type defined by \lstinline{typedef} that define a complex structures that have fields of data objects.
Both atomic data types and complex data types are very close to the data types of C.

\begin{figure}
    \begin{lstlisting}[
        caption={Faulty Mutual Exclusion Algorithm Implemented in \gls{promela} \cite{SpinManual}},
        label={snpt:spin-exm}
    ]
        byte cnt;
        byte x, y, z;

        active [2] proctype user() (*\label{ln:proc}*)
        {
            byte me = _pid + 1;
        again: (*\label{ln:label}*)
            x = me; (*\label{ln:excl-start}*)
            if
            :: (y == 0 || y == me) -> skip
            :: else -> goto again
            fi;

            z = me;
            if
            :: (x == me) -> skip
            :: else -> goto again
            fi;

            y = me;
            if (z = me) -> skip
            :: else -> goto again
            fi; (*\label{ln:excl-end}*)

            cnt++; (*\label{ln:crit-start}*)
            assert(cnt == 1); (*\label{ln:assert}*)
            cnt--; (*\label{ln:crit-end}*)
            goto again
        }
    \end{lstlisting}
\end{figure}

Snippet \ref{snpt:spin-output} shows the output when verifying snippet \ref{snpt:spin-exm} with \gls{spin} where we assume that latter snippet was written into a file called \lstinline{mutex_flaw.pml}.
The lines of the output are structured as follows: at the beginning of each line, you see a step index indicating the progress of all processes, then \lstinline{proc X (NAME)} indicates the process that has made progress by its ID and name.
The rest of the line \lstinline{line X ... [CODE]} shows the code executed by the process along with the corresponding line number in the source file\footnote{%
    In this case, line numbers don't fully align with snippet \ref{snpt:spin-exm} but this is not relevant here.
}.
Notice, how processes 0 and 1 progress completely independent from each other, executing code on a line by line basis where each step of any process counts as a state transition of the whole model.

\begin{figure}
    \begin{lstlisting}[
        caption={\gls{spin} Example Output \cite{SpinManual}},
        label={snpt:spin-output}
    ]
        1:  proc    1 (user) line   5 ... [x = me]
        2:  proc    1 (user) line   8 ... [(((y==0) || (y==me)))]
        3:  proc    1 (user) line  10 ... [z = me]
        4:  proc    1 (user) line  13 ... [((x = me))]
        5:  proc    0 (user) line   5 ... [x = me]
        6:  proc    0 (user) line   8 ... [(((y==0) || (y==me)))]
        7:  proc    1 (user) line  15 ... [y = me]
        8:  proc    1 (user) line  18 ... [((z = me))]
        9:  proc    1 (user) line  22 ... [cnt = cnt+1]
        10: proc    0 (user) line  10 ... [z = me]
        11: proc    0 (user) line  13 ... [((x = me))]
        12: proc    0 (user) line  15 ... [y = me]
        13: proc    0 (user) line  18 ... [((z==me))]
        14: proc    0 (user) line  22 ... [cnt = (cnt+1)]
        spin: line 223 of "mutex_flaw.pml", Error: assertion violated
        spin: text of failed assertion: assert((cnt==1))
        15: proc    0 (user) line  23 ... [assert((cnt==1))]
        spin: trail ends after 15 steps
        # processes: 2
            cnt = 2
            x = 1
            y = 1
            z = 1
        15: proc    1 (user) line  23 "mutex_flaw.pml" (state 20)
        15: proc    0 (user) line  24 "mutex_flaw.pml" (state 21)
        2 processes created
    \end{lstlisting}
\end{figure}

Assertions, however, are not the only way to express properties of \gls{promela} models for \gls{spin}.
Furthermore, there are:
\begin{itemize}
    \item Labels
    \item Never claims
    \item Trace assertions
\end{itemize}

Labels have already been introduced informally along with snippet \ref{snpt:spin-exm}.
To express properties about a model, certain types of labels can be used to give semantics to process state.
For example, you can label a certain part of process code as and end-state that might look like an idling-state to \gls{spin} by default.
% TODO: introduce deadlocks
Idling- and end-states are important to \gls{spin} when it's checking for deadlock-freeness of systems.
By default, if all processes are in an idling-state and wait for some kind of signal, this state is considered to be a deadlock.
However, in some situations it might be perfectly fine for some of the processes to idle in a specific state which should not contribute towards deadlocks.
Labeling parts of code as end-state contributes towards this.

Never claims are processes themselves.
% TODO: introduce LTL
They run like any other process but must not terminate otherwise they're regarded as failure.
This is the most complex way to express properties and in fact falls together with writing LTL properties about a model.
Therefore \gls{spin} also allows to express such never properties in LTL directly via their command line interface.

The last type of properties, trace assertions, solely deal with message passing and therefore are not relevant to this thesis.

For some, it might be obvious at this point why we decided against using \gls{spin} as the model checker of this thesis.
Its focus on verifying distributed and parallel systems is obvious and would make implementing an \gls{isa} in it very hard.
In the \textit{Primer and Reference Manual} for \gls{spin} it is written:
\begin{displaycquote}[p.33]{SpinManual}
    \textins{W}e saw that the emphasis in \gls{promela} models is placed on the coordination and synchronization aspects of a distributed system, and not on its computational aspects. \textelp{}
    The specification language we use for systems verification is therefore deliberately designed to encourage the user to abstract from the purely computational aspects of a design, and to focus on the specification of process interaction at the system level.
\end{displaycquote}

However, the \gls{isa} we will attempt to verify
\begin{enumerate*}[label=\alph*)]
    \item will most likely not include components \enquote{interacting at the system level} and
    \item will be verified on a component level, i.e. computationally as well - even in the case where multiple system level components would be given.
\end{enumerate*}

Furthermore, it is unreasonable to assume that an implementation of instructions of an \gls{isa} could be implemented in a single statement of \gls{promela}.
Yet, this should be the goal as otherwise as shown in snippet \ref{snpt:spin-output} what is regarded as state by \gls{spin} would not fall together with what is regarded as state in an \gls{isa}.
For an \gls{isa}, you typically would consider the \textit{state} of registers and memory to be the state of the \gls{isa} whilst some instruction advances this state.
However, for \gls{spin} more complex state transitions would result in us not being able to differentiate architectural states of the \gls{isa} natively since the process implementing the \gls{isa} would change state on each line of code executed.
This could be circumvented by using the \lstinline{atomic} keyword offered by \gls{promela} which lets you wrap a group of \gls{promela} statements such that they're considered as one atomic statement that advances the process state only by one step.
However, this would lead to a model consisting of one process all of its code being wrapped by one \lstinline{atomic} statement.
This would massively contradict the key idea of \gls{spin} of simple models being \textit{abstracted} from computationally complex code.
In this case, we'd have skipped the whole step of abstracting from some computational model that has distributed components running in parallel.
Not only could this lead to performance issues, it also can be safely assumed that the work for this thesis would be cumbersome and might stumble over obstacles induced by abusing \gls{spin}.

\subsubsection{\muZ{} \& \gls{spacer}}

\muZ{} is a \gls{datalog}-engine that provides querying fixed points with constraints and has been proposed in \cite{Hoder11}.
According to \textit{An Introduction to Database Systems} \cite[p.790ff]{Date00}, \gls{datalog} is a descriptive and querying language that originated in the field of database management systems.
At its core, \gls{datalog} programs are sets of \textit{rules} that combine predicates only using variables and constants to Horn-clauses, i.e. disjunctions with one positive literal at maximum.
For example, consider the following rule $ \pi_0 $ which expresses the transitivity of a predicate $ P $:
\begin{equation*}
    \pi_0 := P(a, b) \land P(b, c) \Rightarrow P(a, c)
\end{equation*}
Such programs are then used to \textit{deduct} facts from the set of rules.
To illustrate what this means, we introduce two other rules.
\begin{align*}
    \pi_1 := & P(0, 1) \Rightarrow \top \\
    \pi_2 := & P(a, b) \Rightarrow P(a + 1, b + 1)
\end{align*}
The \gls{datalog}-program $ \Pi := \{ \pi_0, \pi_1, \pi_2 \} $ now induces the relation $ < $ on all natural numbers including $ 0 $.
$ \pi_1 $ sets up a start of induction which, stating that $ 0 $ is smaller than $ 1 $ which is generalized for all natural numbers by $ \pi_2 $.

Whether or not this exact \gls{datalog}-program is supported by a given \gls{datalog}-engine depends on the extensions implemented by the respective engine.
Our example relies on an extension for scalar operators since we use the $ + $ operator.

As briefly mentioned, \gls{datalog} also supports queries.
\gls{datalog} queries comprise only one predicate and a special head $ ? $.
\begin{equation*}
    q_0 := P(0, x) \Rightarrow \; ?
\end{equation*}
The result to a query is the set of all values for each variable that make the predicate true.
In this case, the result set would be $ \{ 1, 2, 3, \dots \} $.
If no variables but only constants are given in the query, \gls{datalog} simply determines whether the given predicate can be derived for the given constants.

\muZ{} now is a \gls{datalog}-engine that comes as part of the SMT solver z3 \cite{Moura08} and adds support for expressing Horn-clauses to it.
For example, consider the implementation of the program $ \Pi $ for \muZ{} as depicted in snippet \ref{snpt:muz-exm}.
This example yields \smt{sat} as result when executed, meaning, that \smt{goal} can be derived from the rules at hand.

\begin{figure}
    \begin{lstlisting}[
        language=SMT2,
        caption={Implementation of $ \Pi $ for \muZ{}},
        label={snpt:muz-exm}
    ]
        (declare-var a Int)
        (declare-var b Int)
        (declare-var c Int)

        (declare-rel ge (Int Int))
        (declare-rel goal ())

        (rule (ge 0 1))                     ; pi_1
        (rule (=>   (ge a b)                ; pi_2
                    (ge (+ a 1) (+ b 1))))
        (rule (=>   (and (ge a b) (ge b c)) ; pi_0
                    (ge a c)))

        (rule (=>   (ge 10 15)
                    goal))
        (query goal)
    \end{lstlisting}
\end{figure}

\gls{spacer} \cite{Komuravelli13} is an algorithm that combines two widely implemented approaches of currently available formal verification tools: \gls{2bmc} and \gls{cegar}.
In its implementation, \gls{spacer} uses \muZ{} as a backend.
The paper describes those techniques as follows:
\begin{displaycquote}[p.1f]{Komuravelli13}
    The key idea of \gls{2bmc} is to iteratively construct an under-approximation \textins{(or refinement)} $ U $ of the target program $ P $ by unwinding its transition relation and check whether $ U $ is safe using \gls{bmc}.
    If $ U $ is unsafe, so is $ P $.
    Otherwise, a proof $ \pi_U $ is produced explaining \textit{why} $ U $ is safe.
    Finally, $ \pi_U $ is generalized (if possible) to a safety proof of $ P $.
    \textelp{}

    Thea idea of \textins{\gls{cegar}} is to iteratively construct, verify, and refine an abstraction (\textit{i.e.}, an over-approximation) of $ P $ based on abstract counterexamples.
\end{displaycquote}

The key to understand how \gls{spacer} works is to understand what under- or over-approximation of programs are.
For the sake of brevity, consider the program $ P $ as depicted in snippet \ref{snpt:spacer-p}.
$ P $ performs an integer division with remainder for a natural number \lstinline{n} by a divisor \lstinline{div} storing the results in \lstinline{ratio} and \lstinline{mod}.
Intuitively speaking, $ \hat{P} $ is an under-approximation (or abstraction) of $ P $ if for every part of $ P $ there is a corresponding part of $ \hat{P} $ whose effects are logically entailed by the original part.
On the other hand, $ P $ is an over-approximation of $ \hat{P} $.
An example for an over-approximation of $ P $ in snippet \ref{snpt:over-p} and an example for an under-approximation of in snippet \ref{snpt:under-p}.
For abstracting $ P $ to $ \hat{P} $ a couple of lines were removed whilst all other were left untouched.

\begin{figure}
    \centering
    \begin{minipage}{.45\linewidth}
        \begin{lstlisting}[
            linewidth=0.9\linewidth,
            caption={Program $ P $},
            label={snpt:spacer-p}
        ]
            n = abs(input());
            div = abs(input());
            ratio = 0;
            mod = 0;
            n = n - div;
            while (0 <= n) {
                ratio++;
                n = n - div;
            }
            mod = div + n;
        \end{lstlisting}
    \end{minipage}

    \begin{minipage}[t]{.45\linewidth}
        \begin{lstlisting}[
            linewidth=0.9\linewidth,
            caption={Refinement $ \bar{P} $},
            label={snpt:under-p}
        ]
            n = abs(input());
            div = abs(input());
            ratio = 0;
            mod = 0;
            n = n - div;
            if (0 <= n) {
                ratio++;
                n = n - div;
                if (0 <= n) {
                    (*\dots*)
                }
            }
        \end{lstlisting}
    \end{minipage}\hspace{0.1\linewidth}%
    \begin{minipage}[t]{.45\linewidth}
        \begin{lstlisting}[
            linewidth=0.9\linewidth,
            caption={Abstraction $ \hat{P} $},
            label={snpt:over-p},
            showlines=true
        ]
        n = abs(input());
        div = abs(input());
        ratio = 0;
        mod = 0;

        while (0 <= n) {

            n = n - div;
        }

        \end{lstlisting}
    \end{minipage}
\end{figure}

With this example at hand it can more easily be seen how \gls{2bmc} and \gls{cegar} relate to under- and over-approximations respectively.
Assume that we want to prove that always \lstinline{0 <= ratio}.
In the case of the refinement $ \bar{P} $ in snippet \ref{snpt:under-p} we could follow the idea of \gls{2bmc} and iteratively check whether \lstinline{0 <= ratio} for finite traces of $ P $.
If a counterexample is found in $ \bar{P} $ it is obvious that this counterexample must also apply to $ P $.
However, if no counterexample is found but a proof for the property at hand can be constructed one can only hope that this proof can be generalized to $ P $.

On the other hand, the converse holds for over-approximations, i.e. abstractions.
If a property is checked for the abstraction $ \hat{P} $ of $ P $ and a positive result in form of a correctness proof is given this proof will apply to $ P $ as well.
However, when a counterexample is given, it is unclear whether it applies to $ P $.
If the counterexample does not apply to $ P $, the idea of \gls{cegar} \cite{Clark00} is to refine the abstraction at hand in such a way that the counterexample does not apply to it anymore and re-iterate on the verification process.

\gls{spacer} uses both of these techniques to prove safety properties of programs expressed in \gls{datalog} using \muZ{}.
These safety properties are expressed using custom relations in \gls{datalog} such as \smt{goal} in snippet \ref{snpt:muz-exm}.
\gls{spacer} then tries to construct a proof why the property at hand cannot be derived from the axioms of the \gls{datalog} program or it gives a counterexample illustrating a possible weakness of the program.
In theory, \gls{datalog} could be used for the implementation of this thesis.
A single predicate could be used to simulate the architectural state of the instruction set architecture at hand whilst each instruction could be modelled via a separate rule.

However, whereas the limiting factor for \gls{spin} was the modelling language, the limiting factor for \gls{spacer} is the output of the tool.
In case of a property failing to be verified, no counterexamples are given but \gls{spacer} simply outputs there is an trace of the program for which a given property does not hold but without specifying the trace itself.
\muZ{} itself can be configured to give a more detailed result however that would still not include a \textit{trace of derivations}.
For \gls{spacer} or \muZ{} to be usable in the context of this thesis, these tools would need to output a log of variable values or steps taken when applying rules.

\subsubsection{nuXmv}
